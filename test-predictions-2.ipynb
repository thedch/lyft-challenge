{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.imports import *\n",
    "from fastai.transforms import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.model import *\n",
    "from fastai.dataset import *\n",
    "from fastai.sgdr import *\n",
    "from fastai.plots import *\n",
    "\n",
    "import pdb\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data/lyft/train_masks'),\n",
       " PosixPath('data/lyft/train'),\n",
       " PosixPath('data/lyft/models'),\n",
       " PosixPath('data/lyft/tmp')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = Path('data/lyft')\n",
    "list(PATH.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('data/lyft')\n",
    "input_images = PATH/'train'\n",
    "output_images = PATH/'train_masks'\n",
    "\n",
    "def show_img(im, figsize=(8,8), ax=None, alpha=None):\n",
    "    if not ax: fix, ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(im, alpha=alpha)\n",
    "    ax.set_axis_off()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DN = 'train'\n",
    "MASKS_DN = 'train_masks'\n",
    "sz = 128\n",
    "bs = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatchedFilesDatset(FilesDataset):\n",
    "    def __init__(self, filenames, y, transform, path):\n",
    "        assert(len(filenames == len(y)))\n",
    "        self.y = y\n",
    "        super().__init__(filenames, transform, path)\n",
    "        \n",
    "    def get_y(self, i): return open_image(os.path.join(self.path, self.y[i]))\n",
    "    \n",
    "    def get_c(self): return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_names = np.array(list((PATH/TRAIN_DN).iterdir()))\n",
    "y_names = np.array(list((PATH/MASKS_DN).iterdir()))\n",
    "\n",
    "val_idxs = list(range(len(x_names)//5)) # 20% validation split\n",
    "((val_x, trn_x),(val_y, trn_y)) = split_by_idx(val_idxs, x_names, y_names) # split the in/out pairs the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_tfms = [RandomRotate(4, tfm_y=TfmType.CLASS),\n",
    "            RandomFlip(tfm_y=TfmType.CLASS),\n",
    "            RandomLighting(0.05, 0.05)]\n",
    "\n",
    "transforms = tfms_from_model(resnet34, sz, crop_type=CropType.NO, tfm_y=TfmType.CLASS, aug_tfms=aug_tfms)\n",
    "datasets = ImageData.get_ds(MatchedFilesDatset, (trn_x,trn_y), (val_x,val_y), transforms, path='')\n",
    "md = ImageData(PATH, datasets, bs, num_workers=8, classes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StdUpsample(nn.Module):\n",
    "    def __init__(self, nin, nout):\n",
    "        super().__init__()\n",
    "        self.conv = nn.ConvTranspose2d(nin, nout, 2, stride=2)\n",
    "        self.bn = nn.BatchNorm2d(nout)\n",
    "        \n",
    "    def forward(self, x): return self.bn(F.relu(self.conv(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def not_lambda(x): return x[:,0] # TODO: Rename this please\n",
    "\n",
    "flatten_channel = Lambda(not_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_up = nn.Sequential(\n",
    "    nn.ReLU(),\n",
    "    StdUpsample(512,256),\n",
    "    StdUpsample(256,256),\n",
    "    StdUpsample(256,256),\n",
    "    StdUpsample(256,256),\n",
    "    nn.ConvTranspose2d(256, 1, 2, stride=2),\n",
    "    flatten_channel\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ConvnetBuilder(resnet34, 0, 0, 0, custom_head=simple_up)\n",
    "learn = ConvLearner(md, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('road-128')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = open_image(input_images/'100.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f617afd8390>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd4AAAHVCAYAAABfWZoAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAACGhJREFUeJzt3c2N01AUgFFnNFWwZ08TiAqocipA0wRVIKqI2QakRB7jfP47Z41GYUD6dN/zdS7jOA4AQONl7Q8AAGcivAAQEl4ACAkvAISEFwBCwgsAIeEFgJDwAkBIeAEg9Lr2BxiGYfj68t3rswDYtffr22XKnzPxAkBIeAEgJLwAEBJeAAgJLwCEhBcAQsILACHhBYCQ8AJASHgBICS8ABASXgAICS8AhIQXAELCCwAh4QWAkPACQEh4ASAkvAAQEl4ACAkvAISEFwBCwgsAIeEFgJDwAkBIeAEgJLwAEBJeAAgJLwCEhBcAQsILACHhBYCQ8AJASHgBICS8ABASXgAICS8AhIQXAELCCwAh4QWAkPACQEh4ASAkvAAQEl4ACAkvAISEFwBCwgsAIeEFgJDwAkBIeAEgJLwAEBJeAAgJLwCEhBcAQsILACHhBYCQ8AJASHgBICS8ABASXgAICS8AhIQXAELCCwAh4QWAkPACQEh4ASAkvAAQEl4ACAkvAISEFwBCwgsAIeEFgJDwAkBIeAEgJLwAEBJeAAgJLwCEhBcAQsILACHhBYCQ8AJASHgBICS8ABASXgAICS8AhIQXAELCCwAh4QWAkPACQEh4ASAkvAAQEl4ACAkvAISEFwBCwgsAIeEFgJDwAkBIeAEgJLwAEBJeAAgJLwCEhBcAQsILACHhBYCQ8AJASHgBICS8ABASXgAICS8AhIQXAELCCwAh4QWAkPACQEh4ASAkvAAQEl4ACAkvAISEFwBCwgsAIeEFgJDwAkBIeAEgJLwAEBJeAAgJLwCEhBcAQsILACHhBYCQ8AJASHgBICS8ABASXgAICS8AhIQXAELCCwAh4QWAkPACQEh4ASAkvAAQEl4ACAkvAISEFwBCwgsAIeEFgJDwAkBIeAEgJLwAEBJeAAgJLwCEhBcAQsILACHhBYCQ8AJASHgBICS8ABASXgAICS8AhIQXAELCCwAh4QWAkPACQEh4ASAkvAAQEl4ACAkvAISEFwBCwgsAIeEFgJDwAkBIeAEgJLwAEBJeAAgJLwCEhBcAQsILACHhBYCQ8AJASHgBICS8ABASXgAICS8AhIQXAELCCwAh4QWAkPACQEh4ASAkvAAQEl4ACAkvAISEFwBCwgsAIeEFgJDwAkBIeAEgJLwAEBJeAAgJLwCEhBcAQsILACHhBYCQ8AJASHgBICS8ABASXgAICS8AhIQXAELCCwAh4QWAkPACQEh4ASAkvAAQEl4ACAkvAISEFwBCwgsAIeEFgJDwAkBIeAEgJLwAEBJeAAgJLwCEhBcAQsILACHhBYCQ8AJASHgBICS8ABASXgAICS8AhIQXAELCCwAh4QWAkPACQEh4ASAkvAAQEl4ACAkvAISEFwBCwgsAIeEFgJDwAkBIeAEgJLwAEBJeAAgJLwCEhBcAQsILAKHXtT/AM/z49XPxn/nt05fFfyYA52PiBYCQ8AJA6DKO49qfYbj+/rz+h+BDHL0D/O39+naZ8udMvAAQEl4ACAkvAIQOuU7E881Z2XIvDGDiBYCU8AJAyFEzmWe8UWwOR97Amky8ABASXgAICS8AhNzxcjqP7prd/wLPZuIFgJDwAkDIUTPcmLvy5IgamMrECwAh4QWAkPACQEh4ASAkvAAQEl4ACFknggUs/c1L1pPguEy8ABASXgAIOWqGDfJFDnBcJl4ACAkvAISEFwBC7nhhZ+asLrkXhu0w8QJASHgBICS8ABASXgAICS8AhDzVDCcw90scPA0NyzPxAkBIeAEgJLwAEBJeAAgJLwCEhBcAQtaJgLusIcHyTLwAEBJeAAgJLwCEhBcAQsILACHhBYCQdSJgcXPWkKwgcRYmXgAICS8AhIQXAELCCwAh4QWAkPACQMg6EbAJj1aQrBpxJCZeAAgJLwCEhBcAQsILACHhBYCQ8AJAyDoRsHlzvu1oGKwhsU0mXgAICS8AhIQXAELCCwAh4QWAkKeagcO69zS0p51Zk4kXAELCCwAh4QWAkPACQEh4ASAkvAAQsk4EnI4vXWBNJl4ACAkvAISEFwBC7ngBJnp0N+z+l6lMvAAQEl4ACAkvAISEFwBCwgsAIU81AyzAE89MZeIFgJDwAkBIeAEgJLwAEBJeAAgJLwCErBMBPNm9VSNrRudk4gWAkPACQEh4ASAkvAAQEl4ACAkvAISEFwBCwgsAIeEFgJA3VwGs5N4brf6Ht2Ftn4kXAELCCwAh4QWAkPACQEh4ASAkvAAQsk4EsGPWh/bHxAsAIeEFgJDwAkDIHS9M5C5tm57x2sW1+D92DiZeAAgJLwCEHDUzy56PxB4dTe7573VW/s3YGxMvAISEFwBCjpoPxJHbNH5PwJpMvAAQEl4ACAkvAITc8W6QO0iA4zLxAkBIeAEgtImj5r0frd6+Cen27/KRl7fv/XcAwDQmXgAICS8AhIQXAEKbuOPdu3v3s+5tAfiXiRcAQsILACHhBYCQ8AJASHgBICS8ABASXgAICS8AhIQXAELCCwAh4QWAkPACQEh4ASAkvAAQEl4ACAkvAISEFwBCwgsAIeEFgJDwAkBIeAEgJLwAEBJeAAgJLwCEhBcAQsILACHhBYCQ8AJASHgBICS8ABASXgAICS8AhIQXAELCCwAh4QWAkPACQEh4ASAkvAAQEl4ACAkvAISEFwBCwgsAIeEFgJDwAkBIeAEgJLwAEBJeAAgJLwCEhBcAQsILACHhBYCQ8AJASHgBIHQZx3HtzwAAp2HiBYCQ8AJASHgBICS8ABASXgAICS8AhIQXAELCCwAh4QWAkPACQEh4ASAkvAAQEl4ACAkvAISEFwBCwgsAIeEFgJDwAkBIeAEgJLwAEBJeAAgJLwCEhBcAQn8ApQZhf39tMPEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_tfms, val_tfms = transforms\n",
    "aug_t, aug_v = val_tfms(im, im)\n",
    "pred = learn.predict_array(aug_t[None])\n",
    "show_img(pred[0,...]>0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
